{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62f67dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabca126",
   "metadata": {},
   "outputs": [],
   "source": [
    "academic_words =  [\n",
    "                      \"however\", \"therefore\", \"consequently\",\n",
    "                      \"analysis\", \"methodology\", \"significant\",\n",
    "                      \"furthermore\", \"evidence\", \"demonstrates\"\n",
    "                  ]\n",
    "casual_words = [\n",
    "            \"lol\", \"yeah\", \"gonna\", \"wanna\", \"basically\",\n",
    "            \"like\", \"kinda\", \"sorta\"\n",
    "            ]\n",
    "\n",
    "banned_words = [\"shit\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7913ac4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StyleController:\n",
    "    \"\"\"\n",
    "    Modular linguistic/style controller for academic auto-completion.\n",
    "    Works with any HuggingFace-style tokenizer & model.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        tokenizer,\n",
    "        academic_words=academic_words,\n",
    "        casual_words=casual_words,\n",
    "        banned_words=banned_words,\n",
    "        boost=2.0,\n",
    "        penalty=4.0,\n",
    "        use_prefix=True,\n",
    "    ):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.boost = boost\n",
    "        self.penalty = penalty\n",
    "        self.use_prefix = use_prefix\n",
    "\n",
    "        # Default word lists\n",
    "        self.academic_words = academic_words\n",
    "\n",
    "        self.casual_words = casual_words\n",
    "\n",
    "        self.banned_words = banned_words\n",
    "\n",
    "        # Token IDs\n",
    "        self.academic_ids = self._words_to_token_ids(self.academic_words)\n",
    "        self.casual_ids = self._words_to_token_ids(self.casual_words)\n",
    "        self.banned_ids = self._words_to_token_ids(self.banned_words)\n",
    "\n",
    "        # Prefix for academic tone\n",
    "        self.prefix = (\n",
    "            \"Write the continuation below in a formal academic style, \"\n",
    "            \"using precise vocabulary and objective reasoning.\\n\"\n",
    "        )\n",
    "\n",
    "    def _words_to_token_ids(self, words):\n",
    "        ids = []\n",
    "        for w in words:\n",
    "            tokens = self.tokenizer.tokenize(w)\n",
    "            if len(tokens) == 1:\n",
    "                tid = self.tokenizer.convert_tokens_to_ids(tokens[0])\n",
    "                ids.append(tid)\n",
    "        return ids\n",
    "\n",
    "    def apply_prefix(self, text: str):\n",
    "        if self.use_prefix:\n",
    "            return self.prefix + text\n",
    "        return text\n",
    "\n",
    "    def apply_logits_control(self, logits):\n",
    "        \"\"\"Apply style-based logits modification.\"\"\"\n",
    "        # Academic boost\n",
    "        logits[:, self.academic_ids] += self.boost\n",
    "\n",
    "        # Penalize informal language\n",
    "        logits[:, self.casual_ids] -= self.penalty\n",
    "\n",
    "        # Hard ban\n",
    "        logits[:, self.banned_ids] = -1e4\n",
    "\n",
    "        return logits\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
